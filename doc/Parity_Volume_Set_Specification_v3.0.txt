[UNFINISHED DRAFT]  Parity Volume Set Specification 3.0 

Michael Nahas

Started January 16th, 2020
New Design, July 29th, 2021
Updated based on feedback November 16th, 2021  (dropped streaming, added chunks)

\/ \/ \/ TODO \/ \/ \/

License.  --- copyright, "service mark", derivatives

? Drop owner/groupid 
? small files inside the File structure?  ... nah, do tar-then-par
? sparse files?
? special Galoid Field that represents XOR ?
? should an empty filename mean "this file"?
? allow chunks to have a checksum and still not be mapped?  This could be achieved by reserving block index 2^64-1 for the "unmapped block".

/\ /\ /\ TODO /\ /\ /\




Based on Parity Volume Set Specification 2.0 [2003-05-11] by Michael Nahas with ideas from Peter Clements, Paul Nettle, and Ryan Gallagher
Based on Parity Volume Set Specification 1.0 [2001-10-14] by Stefan Wehlus and others.


Introduction:

This document describes a file format for storing redundant data.  If any of the original data is damaged in storage or transmission, the redundant data can be used to regenerate the original input.  Of course, not all damages can be repaired, but many can.

Use Case:

The user selects a set of files from which the redundant data is to be made.  These are known as "input files" and, together with their directory tree, are known as the "input set". The user will provide the input set to a program which generates new files that match the specification in this document.  The program is known as a "Parchive 3.0 client" or "client" for short.  The generated files usually have the extension ".par3" and are known as "Parchive 3.0 files" or "Par3 files".

If the files and directories in the input set ever get damaged (e.g. when they are transmitted unreliably or stored on a faulty disk) the client can read the damaged input files, read the (possibly damaged) Par3 files, and regenerate the original input files and directory tree.  Again, not all damages can be repaired, but many can. 

License:

This document is covered by TODO license.  The full text of the license is in Appendix A. 


Design Goals:

Parchive 3.0's goal is to provide a complete solution for the bottom two layers of archiving: redundancy and splitting.  (Splitting is the breaking of a single archive into multiple files that can be stored on separate disks or multiple packets that can be transmitted.)  Other layers of archiving --- like compression, encryption, and storing metadata --- may be better served by other programs (zip/gzip/7zip, pgp/gpg, tar, etc.)  Parchive 3.0 provides minimal support for some of these layers, for ease and backwards compatibility.

Parchive 3.0 does not provide any support for encryption, because it is tricky to do well.

Major differences from Parchive 2.0 are:
* support empty directories
* support more than 2^16 files
* support UTF-8 (Par2 added this after version 2.0)
* support file permissions, hard links, symbolic links, etc.
* support "incremental backups"
* support files that work both as a Par3 file and another type.  For example, putting recovery data inside a ZIP, ISO 9600 disk image, or other file.
* support for storing data inside a Par3 file (this was optional in Par 2.0)
* support any Galois field that is a multiple of 2^8
* support any linear code (Reed-Solomon, LDPC, random sparse matrix, etc.)
* support for more than 2^16 blocks
* support deduplication, where the same block appears in multiple files
* support "tail packing", where a block holds data from multiple files
* replace MD5 hash (it is both slow and less secure)
* dropped requirement for 4-byte alignment of data

Part of "support any linear code" is to fix the major bug in Parchive 2.0.  Parchive 2.0 did not do Reed-Solomon encoding as it promised.  There was a major mistake in the paper that Parchive 2.0 relied on.  The problem manifested as a bug in Parchive 1.0 and, while Parchive 2.0 reduced its occurrence, it did not fix the problem.  Parchive 2.0 did not use an always invertible matrix; it essentially used a random matrix, which (luckily) is invertible with high probability.  Parchive 3.0 fixes that bug.

The other part of "support any linear code" is supporting non-Reed-Solomon codes.  Those codes can be much faster to compute.  LDPC and sparse random matrices will speed things up dramatically, with a slight increase in errors that cannot be recovered from.

Note: This design focused on redundancy for a set of files on a disk.  This matches the Parchive 1.0 use case of sending files on Usenet, as well as the growing usage of Parchive to protect against faulty disks.  Alternatives were to focus on a redundancy for a stream or to build redundancy into a (user-level) file system.   These are both interesting possibilities, for any open source designers out there.


The Math of Redundancy

The major feature of Parchive is to support redundant data.  Parchive uses Linear Algebra to generate the redundant data and, after damage, to recover the original input data.  To understand how it works, you need to be familiar with vectors, matrices, etc.

The calculation of redundant data starts with the input data being packaged into a set of vectors.  Those vectors are multiplied by the "code matrix" to generate vectors of redundant data.  Thus, the redundant data vector "r" is equal to the code matrix "C" times the input data vector "i": 

r = Ci

Assuming that some data is damaged in transmission or storage, the first step in recovery is identifying the good input data and good redundant data.  Good data is data that arrived intact; bad data was lost or damaged.  We can then permute the elements of each vector to partition them into "good" ones and "bad" ones.  To keep the equation, we also need to permute the rows and columns of the code matrix to match each vector.

r = | r_good |    C = | C_good,good C_good,bad |     i = | i_good |
    | r_bad  |        | C_bad,good  C_bad,bad  |         | i_bad  |

| r_good | = r = Ci = | C_good,good C_good,bad || i_good |
| r_bad  |            | C_bad,good  C_bad,bad  || i_bad  |            


Our goal, of course, is to recover the bad input data.  To do that, we pull out the equation for the good redundant data...

r_good = C_good,good*i_good + C_good,bad*i_bad

... and solve for the bad input data.

i_bad = C_good,bad^-1*(r_good - C_good,good*i_good) 

Here, "^-1" indicates the left inverse of the matrix.  Since the redundant data was made by multiplying the input data by the code matrix, the inverse of the code matrix allows us to recreate the missing input data from the redundant data.  Not every matrix has a left inverse.  When the left inverse does not exist, we cannot recover the input data.  A left inverse never exists when the matrix has more columns than rows, which means we cannot recover if there are more bad input blocks than good redundant blocks.

Unlike in your Linear Algebra class, the elements of the vectors and matrices are not real numbers or complex numbers, but elements of a "Galois field".  Like the computer's integers (a.k.a., the integers modulo 2^N), Galois fields come in various sizes like 8-bits, 16-bits, etc. and support operations called addition, subtraction, multiplication, and division.  Unlike the computer's integers, "division" exactly inverts "multiplication" for every value.  (Computer integers can overflow during multiplication, preventing division from inverting the multiplication.)  That perfect inversion allows the Linear Algebra to work.

Parchive 3.0 improves on Parchive 2.0 by supporting multiple Galois fields and by supporting any code matrix.  This means Parchive 3.0 supports a large set of error correcting codes known as "linear codes".  These include Reed-Solomon and many Low Density Parity Check (LDPC) codes.  This flexibility allows Parchive 3.0 clients to choose between speed and the number of errors that can be recovered.  It also allows Parchive 3.0 to support any new linear code.



Specifics of Computation 

This section goes into the details of how redundant data is computed and how recovery proceeds.  That is, how the mathematical vectors used in the previous section are related to actual bytes in a file.

Generating the recovery data starts with choosing a Galois field and block size.  The Galois field is usually chosen based on whatever is fastest for the computer's hardware.  For this example, it fits in 2-bytes (16-bits).  The block size is the smallest unit for recovering data.  It is usually chosen to match the transmission/storage technology or to limit overhead.  The block size must be a multiple of the size of the Galois field.  For this example, it will be 2048 bytes, but in practice it can be much larger, even gigabytes.

First, all of the input data is packed into equal-sized blocks.  There are many steps to this.  What follows is a list of the operations, but the specifics of each will be described in detail later.  A client can do "deduplication" and break the files into variable-length chunks that are each unique.  Or a client can skip this step and make each file its own chunk.  The chunks are then chopped into equal-sized block.  If the end of a chunk doesn't completely fill a block, it can be packed with the ends of other chunks into a single block.  Lastly, any incompletely filled block is filled with zero bytes.  By the end of these operations, the input data is converted to equal-sized blocks.  For this example, the input data is broken up into 100 blocks, each 2048 bytes long.  Each of those 100 blocks can be seen as holding 1024 Galois field values (each 2-byte in size).  

The next step reorganizes the blocks into vectors.  The 100 blocks containing 1024 Galois field values becomes 1024 vectors containing 100 Galois field values.  This is done the obvious way: swapping rows for columns and columns for rows.  The values in the i-th block become the i-th element of each vector; the j-th value in each block are used to make the j-th vector.   

Next, the user chooses the numbers of recovery blocks that they want. The number of recovery blocks determines the maximum number of damaged/missing input blocks that we can recover.  Often the number of recovery blocks is 5% or 10% of the number of input blocks. 

Next, the user chooses a code matrix.  The code matrix has a column for each input block and a row for each recovery block.  The elements of the matrix can be anything --- Parchive 3.0 supports any linear code.  Codes vary in speed and the probability of recovering from an error.  Some common choices for the code matrix will be a Cauchy matrix, for recovering any possible damage, or a sparse random matrix, for speed.

Next, for each input vector, we make a recovery vector by multiplying the input vector with the code matrix.  There is only one code matrix; the code matrix is the same for every pair of vectors.  Since there is one recovery vector for each input vector, there are 1024 recovery vectors.  The length of each recovery vector is equal to how many recovery blocks we want.  

The next step reorganizes the recovery vectors into recovery blocks.  It is basically the inverse of the step that reorganized the input blocks into input vectors.  If we want 5 recovery blocks, the 1024 recovery vectors of length 5 become 5 recovery blocks with 1024 Galois field values.  The i-th element in each vector goes into the i-th recovery block; the j-th vector is used to make the j-th value in each recovery block.  Notice that the recovery blocks are the same size as the input blocks.  Each has 1024 Galois field values and each value takes 2-bytes, so the recovery blocks are each 2048 bytes.

The recovery blocks are stored in the Recovery packets (specified below) and written to a Par3 file.  The input blocks can be stored in their original files or stored in Data packets (specified below) and put in the Par3 file(s).   The Par3 file(s) contain a checksum for every input and recovery block.  After the Par3 file(s) are stored or transmitted, the checksums are used to determine which blocks are damaged.

After storage or transmission, if there are any input blocks missing or damaged, we need to do recovery.  

The first step of recovery is identify elements of the input vectors associated with the missing/damaged input blocks.

Next, we identify elements of the recovery vectors associated with the missing/damaged recovery block.

Next, we perform the math (described above) which uses the good elements of each recovery vector to recover the bad elements of its associated input vector.  The math requires inverting a submatrix of the code matrix and, if the left inverse does not exist, we fail.  There are many ways to invert a matrix (E.g., Gaussian elimination, Fast Fourier Transform (FFT), and the incremental approach used by LDPC).  Clients may consider multiple strategies.

After recovering the missing elements of each input vector, the data is reorganized to regenerate the missing input blocks.  Those blocks are written to the appropriate files.  The Par3 file contains a checksum for all the data sent to make sure that the repair process worked correctly.

Having covered the math behind recovery and how the bytes are manipulated to fit the math, we can go into the details of the specification.  


Conventions:

There are a number of conventions used in this specification.

The abbreviation "kB" refers to 2^10 = 1,024 bytes.  (Disk sales people have sometimes used "kilobyte" or "kB" to mean 10^3 = 1,000 bytes.  The result was the unambiguous but little used "kibibyte" or "KiB".)  

All integers in this version of the spec are integers of 2, 4, 8, or 16 bytes in length.

All integers are little endian. (This is the default on x86 and x86-64 CPUs, but not other architectures.)  Signed integers are in 2's complement notation.  (This is the default on every major architecture.)  

Strings are not NUL-terminated.  This is to prevent hackers from using stack-overflow attacks.  If an N-byte field contains an array, a null-terminated string can be created by copying the N-byte field into a character array of length N+1 and then the setting the N+1 character to '\0'.

The lengths of arrays and strings are often implicit.  For example, if a region is known to be 32 bytes and that region contains an 8-byte integer and a string, then the string is known to take up 24 bytes.  

All strings are UTF-8.  WARNING: Writers of OSX/MacOS clients must take special care with UTF-8 filenames!  Unicode has multiple ways to encode the same string.  An e with an accent mark can be encoded as a single character (U+00e9) or two characters, one for the e (U+0065) and one for the accent mark (U+0301).  Par3 does not require a particular encoding.  Forcing a particular encoding is called "normalization" in the Unicode vocabulary.  Most file systems do not normalize filenames and just treat the UTF-8 as a sequence of bytes.  Par3 follows their practice.  However, HFS+ was Apple's default file system from 1998 to 2017 and it normalizes every filename.  Thus, if a Parchive 3.0 client writes a file with a UTF-8 filename, the HFS+ file system may change the filename.  Clients for OSX/MacOS should be aware of this possibility.  Apple's current default file system, APFS, does not do normalization.  

The lengths of input files and locations in input files can be 8-byte integers or larger.  There is no limit on the length of a Par3 file.  (Hard drive size doubles every 1.5 years and is expected to exceed 8-byte integers before 2040.)  Clients MAY choose not to support files that are larger than 2^64.  Clients that do not support large files must inform the user if they encounter a Par3 file containing too large a file.

The block size and matrix indices are 8-bytes integers.  In order to protect files with more than 2^64 bytes, users must choose larger block sizes.  

Par3 uses multiple hash functions.  The "rolling hash" is CRC32C.  It is used to identify input blocks that are not in their expected location.  This hash is only 32 bits long and may not uniquely identify a block.  

The "fingerprint hash" is KangarooTwelve hash, a.k.a. K12 hash.  It is used to uniquely identify blocks.  If two blocks have the same fingerprint hash, they are assumed to have identical contents.  

Every byte of a Par3 file is specified.  Padding between packets, if done at all, is specified to be zero bytes.  The order of items in all arrays is specified.

When discussing vectors and matrices, this document uses zero-indexing.  That is, the elements in a vector are at locations 0 through N-1.  (One-indexing, the usual convention in mathematics, has them at locations 1 through N.)


Packets

A Par3 file is made of packets - self-contained parts with their own checksum. This design prevents damage to one part of the file from making the whole file unusable.  

Packets have a type and each type of packet serves a different purpose.  One type describes the code matrix.  Another contains input blocks.  Yet another contains a recovery block.  There are many other types.

A Par3 file is only required to contain 1 specific packet - the packet that identifies the client that created the file.  This way, if clients are creating files that don't match the specification in some way, they can be tracked down.

All packets contain an InputSetID.  It uniquely identifies the set of input files and directories.  The packets to recover a particular set of input files can be stored in multiple Par3 files.  In that case, the packets can be identified because they will all share the same InputSetID.  The packets to recover different sets of input files can be stored inside the same Par3 file.  In that case, the packets can be told apart by their different InputSetIDs.  To handle incremental backups, an InputSetID can have a "parent" InputSetID.  With a few exceptions, the packets of the parent (and any of its parents), are considered packets of the child InputSetID.  

Packets can be duplicated.  In fact, duplicating packets is recommended for vital packets, such as the one containing the file checksums.

Packets can appear in any order.  Because packets can be lost or mishandled, we cannot guarantee the order that packets arrive at the receiving client.  Nonetheless, there is a recommended order that, if most packets arrive correctly, allows receiving clients to recover the files in a single pass.  



Packet Header

A Par3 file consists of a sequence of "packets". A packet has a fixed-sized header and a variable length body.  The fields of the header are:

Table: Packet Header
Length (bytes)	Type	Description
8	byte[8]	Magic sequence. Used to quickly identify location of packets. Value = {'P', 'A', 'R', '3', '\0', 'P', 'K', 'T'} (ASCII)
16	fingerprint hash	K12 Hash of packet. Used as a checksum for the packet. Calculation starts after this field and ends at last byte of body. Does not include the magic sequence or this field.  
8	unsigned int	Length of the entire packet.  (NB: Includes length of header.)
8	InputSetID       All packets for the same input set have the same InputSetID. (See below for how it is calculated.)
8	byte[8]	  Packet type. Can be any value. All beginning "PAR " (ASCII) are reserved for specification-defined packets.  Application-specific packets must have an application-specific 4-byte prefix.  
?	?	Body of Packet. 

The magic sequence is a constant value that is the same in every packet.  It is used when searching for packets in a file.  (The magic sequence begins with "PAR3\0" so that if someone looks at the contents of a Par3 file in a text editor, it starts with "PAR3".)

The checksum is used to determine if any part of the packet has been changed.  The checksum does not cover the magic sequence nor the checksum field itself; it covers everything after (including all of the body).  If the field's value does not match the checksum of the data received, the packet is ignored.

The length of the entire packet is measured in bytes.  It includes the length of header.  (NOTE: In Par 3, packets are not required to be 4-byte aligned and packet lengths are not required to be a multiple of 4-bytes.  If a client wished to align packets, 0-bytes can be inserted between packets.)

The InputSetID is used to identify packets that should be processed together, even if those packets were written to separate Par3 files.  The InputSetID is a globally unique random number.  See the Start packet description below for an explanation of how it is generated.

The packet-type field is used to distinguish the different types of packets.  Clients MUST be able to process the "core" packet types listed below.  Client MAY process the optional packets or create their own application-specific packets.   The packet type is not guaranteed to be a string or even ASCII valued.  (NOTE: The types of required packets are ASCII strings so that a developer can run "strings file | grep PAR" and see what packets are in a file.)  If the client does not recognize the packet type, the packet is ignored.  

The body contains data that is particular to the packet type.  There are various types of packets. The "core" set of packets - the set of packets that all clients must recognize and process - are listed next. For each, the value for the "type" field will be listed along with the contents of the body of the packet. 


Creator packet

This packet is used to identify the client that created the Par3 file.  It is required to be in every Par3 file.

This packet is used for debugging.  If a decoding client is unable to recover the input set due to a badly created file, the contents of the creator packet MUST be shown to the user.  (An automated system MUST write the information to a log file.)  The goal of this is that any client incompatibilities can be found and resolved quickly.

The Creator packet has a type value of "PAR CRE\0" (ASCII). The packet's body contains the following:

Table: Creator Packet Body Contents
Length (bytes)	Type	Description
?	UTF-8 string	UTF-8 text identifying the client, options, and contact information.  Reminder: This is not a null terminated string.

The text in the Creator packet MUST identify the client that created the file, including the version number of the client.

It is RECOMMENDED that the text also include the parameters used to generate the Par3 file.  For example, a command-line tool could include all the command-line options.  A GUI client might include a snippet of the program's log file.

It is RECOMMENDED the text include a way to contact the author of the tool.  E.g., an email address or the URL of a web page for submitting new issues.  


Comment packet

The Comment packet contains a comment in UTF-8.  This string SHOULD be shown to the user.  (An automated system SHOULD write the information to a log file.)  If multiple copies of the same Comment packet are found, only one should be shown.

The Comment packet has a type value of "PAR COM\0" (ASCII). The packet's body contains the following

Table Comment Packet Contents
Length (bytes)	Type	Description
?	UTF-8 string	The comment. NB: This is not a null terminated string!



Start packet

This packet specifies the Galois field and block size.  If the set of input files shares data with a previous set, this packet holds the InputSetID of the "parent" input set.

The Start packet has a type value of "PAR STA\0" (ASCII). The packet's body contains the following:

Table: Start Packet Body Contents
Length (bytes)	Type	Description
8	InputSetID	The "parent" InputSetID, or zeros if none.
16      fingerprint hash 	The checksum of the parent's Root packet, or random if none.
8	unsigned int	block size in bytes
8	unsigned int	The size of the Galois field in bytes.
?	?-byte GF	The generator of the Galois field without its leading 1.


The first field is used in the case of an "incremental backup".  If this input set is an incremental backup of another input set, the field is set to the InputSetID of the parent.  Otherwise, the field is all zeros.  If the field is set, all the packets with the parent's InputSetID (and any of its ancestors) are considered packets with this packet's InputSetID with the following conditions.  First, the ancestors' Root packets are not used to determine the input set.  Second, the ancestors' Start packets must have the same Galois field and block-size as this packet.  

The second field is the checksum of the parent's Root packet, or a random number if there is no parent.  The checksum of the parent's Root packet guarantees that the parent's input set was complete specified before this input set's was started.  If there is no parent, the value is a global unique number. The globally unique number ensures the InputSetID (explained below) is unique.  

NOTE: One way to generate a globally unique number is to use the fingerprint hash of the triple consisting of: a machine identifier, a process identifier, and a high-resolution timestamp.  (Be careful that the machine identifier is actually unique!  Many computers share the same IP Address in one of the private address ranges.)  Another method for generating a globally unique number is, if the input set's data is known ahead of time, is to use a fingerprint hash of the block size, Galois field parameters, and all the files' contents.

The block size determines the length of input blocks and recovery blocks.  They are the same size.  The block size must be a multiple of the Galois field size.  If there is a parent InputSetID, the block size must be the same as the parent's. 

The Galois field size says how many bytes are used to hold a Galois field element.  If there is a parent InputSetID, the Galois field (both size and generator) must be the same as in the parent. 

The Galois field's generator is written in little-endian format without its leading 1.  Thus, if the Galois field had a size of 2-bytes and a generator of 0x1100B, the entry's first two bytes would hold the value 0x100B in little-endian format.  Notice that the packet does not store the leading 1 that is present in the mathematical notation of the generator.  There is more on Galois fields later in this specification.  



There is only one Start packet for an InputSetID.  There can be multiple identical copies of this packet in the file.  (This is true for all packets.)

Start packets are used to generate the InputSetID, which is included in the header of every packet.  The InputSetID is the first 8 bytes of the K12 hash of the body of the Start packet.  To be clear, the hash for the InputSetID does not include the header of the packet.  (Including the header is actually impossible, since the hash would have to contain a hash of itself!)  


Data Packet

This packet contains one block of data from the input files.

The Data packet has a type value of "PAR DAT\0" (ASCII). The packet's body contains the following:

Table: Data Packet Body Contents
Length (bytes)	Type	Description
8	unsigned int	The index of the input block 
?	byte[] 	 	The data itself. 

The input block's index is used with the File packets (describe below) to say where this data occurs in files.  Input block indices are used consecutively, so an input set will generally use all block indices from 0 up to a particular value.

The data's length is implicit.  (The packet's entire length is written in the packet header.)   Data packets contain an entire block's worth of data.  If the data's length is less than the block size, the rest of the block will be filled with zero bytes.  The data cannot be larger than the block size.



External Data Packet

This packet contains checksums for input blocks that are not stored inside a Data packet.  The most common case is when input files are kept around and have the data inside them.  Should those files be partially damaged, the good data stored in them can be used for recovery.  The checksums in this packet are used to identify that data and tell what parts are good.

The External Data packet has a type value of "PAR EXT\0" (ASCII). The packet's body contains the following:

Table: External Data Packet Body Contents
Length (bytes)	Type	Description
8	unsigned int	Index of the first input block
16*?	{rolling hash, 12-byte fingerprint hash} A rolling checksum and finger print for each input block

The index for the first input block for which there is a checksum.  

The tuples contain a rolling hash (CRC32) and the lower 12 bytes of the fingerprint hash (K12 hash) for each block in a sequence of input blocks.  Thus, the first pair of checksums is for a block that starts at the index times the block size and goes for block size bytes.  The second pair of check sums is for the following block.  Etc.

Note: The rolling hash is used to locate a block when data might have shifted location.  The fingerprint hash is used to confirm that the block is the right block (because the rolling hash is less trustworthy).  There is more about the rolling hash in the section "Rolling Hash" below.



Matrix Packets

A matrix packet determines a portion of the code matrix and specifies how one or more recovery blocks were computed.  There are 3 different types matrix packets.  More than one type can be used at the same time.  For example, a sparse matrix packet could be used to generate most recovery data and a Cauchy matrix packet to generate a few blocks of recovery data.  (This dual approach balances speed and recovery of errors.)


Matrix Packets

Parchive 3.0 has 3 different types of matrix packets: Cauchy, Sparse Random, and Explicit.

Cauchy Matrix Packet

This packet describes a Cauchy matrix.  It is used for all or part of the code matrix.  A single Cauchy Matrix packet determines multiple rows of the code matrix and can be used with multiple Recovery Data packets.

The Cauchy matrix creates the best possible recovery data.  With the Cauchy matrix, any submatrix that can have a left inverse does have a left inverse.  (That is, any submatrix which doesn't have more columns than rows, has a left inverse.)  Using just one Cauchy matrix creates a Reed-Solomon code.  

The Cauchy matrix packet has a type value of "PAR CAU\0" (ASCII). The packet's body contains the following:

Table: Cauchy Packet Body Contents
Length (bytes)	Type	Description
8	unsigned int	Index of first input block 
8	unsigned int	Index of last input block plus 1
8	unsigned int	hint for number of recovery blocks

The recovery data is computed for a range of input blocks.  The range is denoted using a "half-open interval".  So, to compute recovery blocks for input blocks 3, 4, and 5, the range is denoted by 3 and 6.  If the sending client wants to compute recovery data for every input block, they can send values 0 and 0.  (Because the maximum unsigned integer plus 1 rolls over to 0.)  The matrix's elements for all input blocks outside the range is 0.

The hint to the number of recovery blocks is used in single-pass situations to allocate buffers.  If the number of rows is unknown, the hint is set to zero.  

Otherwise, the matrix's element for input block I and recovery block R depends on I and R.  (NOTE: This specification uses zero-index vectors, so I and R start at 0.)   Specifically, it is the multiplicative inverse of x_I-y_R, where x_I is the Galois field element with the same bit pattern as binary integer I+1 and y_R is the Galois field element associated with the binary integer MAX-R, where MAX is the maximum binary integer value with the same size as the Galois field.  (NOTE: In binary, MAX contains all ones.)  To be clear, the multiplicative inverse and subtraction x_I-y_R are done using Galois field arithmetic.  The I+1 addition and MAX-R subtraction is done using native integer arithmetic.

Mathematically, that is: inv( (I+1) ^ (~0-R) ) = inv( (-2-I) ^ R ) where the GF element fits in an twos-compliment integer, "inv()" is the Galois field's multiplicative inverse, and "^" denotes XOR.


Sparse Random Matrix Packet

This packet describes a sparse random matrix.  It is faster to calculate recovery blocks with a sparse matrix, if the user is willing to accept a slightly higher chance of not recovering from extreme cases.

A sparse random NxN matrix with at least N*ln(N) non-zero elements has rank N-K for some small K.  When ln(N)>3 or, equivalently N>20, large values of K are very very rare.  Invertible matrices have rank N, so these sparse random matrices are very very close to being invertible.

To be specific about K and the rank, the probability for the rank to be less than N-K for a given K is proportional to 1/(g^K) where g is the number of unique Galois field values.  Thus, if matrix's elements are from a 1-byte Galois field with 256 values, the probably that the rank is less than N-3 is proportional to 1/(256^3) or less than one-in-a-million.  For details, see "The Rank of Sparse Random Matrices over Finite Fields" by Blomer, Karp, and Welzl.

Thus, if the recovery submatrix (called "C_good,bad" earlier) is NxN with at least N*ln(N) randomly non-zero elements and ln(N)>3 (or, equivalently, N>20), we can recovery almost all the input blocks.  Specifically, N-K of them.  And, if we augment the random matrix with K recovery blocks generated from a Cauchy matrix, which recover any missing input blocks, we are very very likely to recover all the input blocks.  

Given this, how many random recovery blocks and Cauchy recovery blocks should be generated?  If there are B input blocks and we want them to survive a maximum perfectly-random failure rate F and use contant K, then the number of sparse random recovery blocks should be B*F/(1-F) and the number of Cauchy recovery blocks should be K/(1-F).  The probability of a non-zero element in the sparse random matrix must be at least ln(N)/N, where N=B*F.  Please keep in mind that the math only works when ln(N)>3 or, eqivalently, N>20.  WARNING: the math in this paragraph was done using expected values, not proper probability distributions, and may under estimate the probability of some events, such as losing multiple Cauchy recovery blocks, which could affect the probability of recovery.  

If it feels wrong to increase the probability of failure, recall that for any matrix, it must fail if B-1 or fewer input and recovery blocks arrive.  Using a sparse matrix, rather than a Cauchy, can be up to N/ln(N) times faster.  Users that can store/send a few additional recovery blocks can get much faster performance with a miniscule increase in failure to recover.

The Sparse Random Matrix packet has a type value of "PAR SPA\0" (ASCII). The packet's body contains the following:

Table: Sparse Random Matrix Packet Body Contents
Length (bytes)	Type	Description
8	unsigned int	Index of first input block 
8	unsigned int	Index of last input block plus 1
8	unsigned int	maximum number of recovery blocks
8       unsigned int	number of non-zero elements per input block
8	unsigned int    random number generator seed

The recovery data is computed for a range of input blocks.  (See Cauchy Matrix packet.)  The matrix's elements for all input blocks outside the range is 0.

Otherwise, each input block's non-zero elements are generated and then shuffled into position.  The following paragraphs describe the details.

1. Allocate a matrix with R rows and C columns, where R is the number of input blocks and C is the number of recovery blocks

2. Go row-by-row from low index to high, generating each row as follows:

2.a. Fill the row with C-X zeroes and X random Galois field values.  The zeroes go in the low indexes; the random values in the higher ones.  The method for generating the random Galois field values is below.  The order of requests to the random number generator is important: the values should be assigned from the lowest column index to the greatest.  

2.b. Shuffle the row.  The random non-zero values will then be evenly distributed.  The shuffle algorithm is the "inside-out" version of the "Fisher-Yates shuffle".  Skip the shuffle for the first C-X elements, because they are all zeroes.  The first non-zero value is at index C-X and is swapped with a random location in the range 0 to C-X.  The next non-zero value is at index C-X+1 and is swapped with a random location in the range 0 to C-X+1.  Continue until all the non-zero elements are shuffled.  The random locations are generated by treating a random 64-bit value as an unsigned integer and using modulus (the % operator in C, C++, Java, python, etc.).  Be careful that the value is treated as an unsigned value, and not a signed one. 

How to generate a B-byte random non-zero Galois field value:  If B is greater than 8-bytes, the 64-bit values from the random number generator are put into the Galois field value from lowest byte-index to highest.  For the last (B modulo 8) bytes, the lowest bits of the random 64-bit value are used.  This is the same as if the random value was taken modulo 2^(8*B).  Lastly, if the random value was zero, it should be ignored and completely regenerated.  

The final result is a matrix where every row has X randomly-located non-zero random values.  This will mean data from from each input block will be incorporated into X different recovery blocks.  



Explicit Matrix Packet

This packet describes a matrix that computes a single recovery block.  The values of the elements are explicitly contained in the packet, and not computed like the other matrix packets.  It is intended to be used for LDPC, such as Tornado Codes.

The Explicit Matrix rows packet has a type value of "PAR EXP\0" (ASCII). The packet's body contains the following:

Table: Explicit Matrix Packet Body Contents
Length (bytes)	Type	Description
?*(8+?)	{8-byte unsigned int, GF value}	zero-indexed input block, Galois field value

The matrix contains values for a single row of the code matrix.  There will be only one recovery block associated with this matrix.  For each input block that is used to calculate the recovery block, there is a pair of the index of the input block and its Galois field factor.  The pairs are in sorted order, with input block indices increasing from lowest to highest.  (Any indices not mentioned are assumed to have a factor of zero.)



Recovery Data Packet

This packet contains a recovery block.

The Recovery Data packet has a type value of "PAR REC\0" (ASCII). The packet's body contains the following:

Table: Recovery Data Packet Body Contents
Length (bytes)	Type	Description
16	fingerprint hash	The checksum from the Matrix packet
16	fingerprint hash	The checksum from the Root packet
8	unsigned int	The index of the recovery block
?	data	 	The recovery block data

The recovery block data is calculated using the code matrix as determined by the Matrix packet checksum.  Notice that the index of the recovery block is dependent upon the Matrix packet.  For example, in a Par3 file using Explicit Matrix packets, there will be a Recovery Data packet for each Explicit Matrix packet and all the Recovery Data packets will have 0 for the index of the recovery block.

The recovery data is only calculated using complete data blocks up to the maximum used input block index as recorded in the Root packet.  

Note: When recovering from an "incremental backup", the parent's Recovery Data packets cannot be used to recover data written by the child.  This is recorded in the Recovery Data packet by the Root packet hash.  Root packet contains the "lowest unused input block index" value, which will be lower for the parent than the child.


File Packet

This represent a file in the input set.

Parchive 3.0's default behavior is to ignore all metadata except for the filename (and directory location, which is stored elsewhere).  Since each file system stores a different set of metadata, there are optional packets that can store the metadata for some file systems.  

The File packet has a type value of "PAR FIL\0" (ASCII). The packet's body contains the following:

Table: File Packet Body Contents
Length (bytes)	Type	Description
2      unsigned int	length of filename
?      UTF-8 string    filename
16     fingerprint hash	hash of the first 16kB of the file
?*?    {8-byte unsigned int, fingerprint hash or zeros, [OPTIONAL: 8-byte unsigned int], [OPTIONAL: rolling hash, fingerprint hash, 8-byte unsigned int; 8-byte unsigned int]}	chuck length, hash, [first block index], [tail hash, tail hash, tail block index, offset in block]

The first entry holds the length of the filename.  (FYI: 255 bytes is the limit on NTFS, EXT4, and exFAT.  ReiserFS supports 255 characters, in up to 4kB of storage.)

The filename is a UTF-8 string.  It is not NUL-terminated.

The hash of the first 16kB of the file is used to identify files that have been moved or renamed.  This is only a hint --- any bytes at the front of a file might have been damaged (deleted/replaced/added).

The last field is sequence of chunk descriptions.  The input file is divided into a sequence of variable-length chunks and the chunk descriptions explain how to map each chunk to input blocks.  The chunks cover the file and do not overlap. The chunk descriptions are in order.  Thus, the location of a chuck is be determined by summing the lengths of the preceding chunks.  The length of the file can be determined by summing the length of all the chunks.

The chunk description starts with the length of the chunk and a fingerprint hash of the chunk's entire contents.  If the chunk's contents is unknown and not protected by the recovery data, the fingerprint hash value is set to all zeroes.  (This is used with the "Par inside" feature described below.)  If the chunk's length is at least 1 block-size and the fingerprint hash is not zeroed, the next field holds the index of the first input block mapped to the chunk's data.  That first input block holds the first block-size of the chunk's data.  The rest of the chunk's data is mapped to the subsequent input blocks, except, should it exists, the final fraction of a block.  If the chunk's size is not a multiple of block-size and the fingerprint hash is not zeroed, the final 4 fields cover the "tail" of the file.  They are a rolling hash of the tail, a fingerprint hash of the tail, the index of the input block holding the tail's data, and the offset of the tail inside that block.  The tail must be completely contained by the single input block holding it.


Note: The filename is a filename, not a path.  

Note: See the security section of this document about checking filenames to avoid security breaches.  The security section also has suggestions on selecting filenames that will be portable across file systems.

Note: When assigning the indexes of input blocks used to hold data, clients should generally assign them in increasing order, starting at 0.  Higher values are left for "incremental backups" who use this input set as a parent.  

Note: Simple clients will probably write Par3 files where each input file consist of a single chunk.  More complex clients may use rolling hashes or "content-defined chunking" or version control data to identify files that share content.  In those cases, the same chunk description may appear in multiple File packets or, even, appear multiple times inside the same File packet.  Nonetheless, all clients MUST be able to decoded File packets with multiple chunk descriptions and perform recovery. 

Note: Simple clients can put each "tail" of a chunk into its own input block with a zero offset.  More complex clients may pack multiple "tails" into the same input block.  Nonetheless, all clients MUST be able to decoded File packets where multiple tails are packed into the same input block and perform recovery.

Note: Chunk descriptions can overlap input blocks without being identical.  Tails of files can overlap inside the same input block.  Neither of these cases is expected to be common, but they are allowed by the current version of the specification.




Directory Packet

This packet represent a sub-directory holding files from the input set.

Parchive 3.0's default behavior is to ignore all metadata except for the directory's name (and location in parent directories).   Since each file system stores a different set of metadata, there are optional packets that can store the metadata for some file systems.  

The File packet has a type value of "PAR DIR\0" (ASCII). The packet's body contains the following:

Table: Directory Packet Body Contents
Length (bytes)	Type	Description
2      unsigned int    length of string
?      UTF-8 string    name of directory
?*16	fingerprint hash       checksums of File and Directory packets

The first byte is the length of the directory's name.  (255 bytes is the limit on NTFS, EXT4, and exFAT.  ReiserFS supports 255 characters, in up to 4kB of storage.)

The directory's name is a UTF-8 string.  It is not NUL-terminated. 

For each file and subdirectory contained in the directory, the checksum of the associated File packet or Directory packet is contained in the Directory packet.  (You can see that directories containing themselves is impossible in this format.)  The checksums are in numerical order.  It is not allowed to have the hashes of two Files or Directories with the same name in the Directory packet.  

\/ \/ \/ TODO \/ \/ \/

Instead of "in numerical order", should File and Directory packets be in alphabetical order?  Or, to precisely handle Unicode, lexical numerical order?  That way, preventing ones with duplicate names will be a easier.  Plus, clients are likely to traverse Files/Dirs in that order.  (And lookup would be faster?)

OR, not require any order?

/\ /\ /\ TODO /\ /\ /\

Note: The Directory packet and the File and Directory packets reachable by following hashes represent a tree.  Every supported file system supports a directory tree.  Some file systems, like EXT4 and NTFS, support a directed acyclic graph or "DAG", while others, like FAT and exFAT, do not.   It is valid for the hash of a File or Directory packet to appear inside multiple Directory packets.  When that occurs, it represents a complete copy of the file or subdirectory.  It is not a hard link.  A common occurrence of this would be 2 different empty directories with the same name.  See the Link packet to see how DAGs are supported by hard links.

Note: Parchive 3.0 supports empty directories. 



Root Packet

This packet identifies the top directory in the directory tree holding the input set.  

The Root packet has a type value of "PAR ROO\0" (ASCII). The packet's body contains the following:

Table: Root Packet Body Contents
Length (bytes)	Type	Description
8	unsigned int	Lowest unused index for input blocks.
1	unsigned int   attributes
?*16	fingerprint hash       checksums of File and Directory packets

The first field holds the lowest unused index for input blocks.  If a client generates an "incremental backup" with this packet's input set as the parent, that client can start assigning new input blocks for new data at that index.

The attributes is a bit field.  At the moment, only the least significant bit is used.  If it is 0, the directory is a relative path.  If it is 1, the directory is an absolute path.   All bits besides the least significant bit must be set to zero.

For each file and subdirectory contained in the top-level directory, the checksum of the associated File packet or Directory packet is contained in the Root packet.  This is similar to the Directory packet. The checksums are in numerical order.  It is not allowed to have the hashes of two Files or Directories with the same name in the Root packet.  

There is at most one Root packet with a given InputSetID.  The packet can be duplicated.

Note:  The Root packet's checksum represents a checksum for the entire input set. 

Note: Since the Root packet acts like a directory, its contents have the same restrictions as the Directory packet. 

Note: The Root packet's header contains the InputSetID, which is the checksum of the Start packet.  The Start packet contains the checksum of the parent's Root packet.  Thus, the complete chain of ancestors is determined by Start/Root packets.  

Note: If the input set consisted of one file "/usr/bin/bash", it would be encoded: Root(absolute)->Directory("usr")->Directory("bin")->File("bash",...)   If it was one file "src/foo.c", it would be encoded: Root(relative)->Directory(src)->File("foo.c", ...).  The "->" indicates including the hash of the packet on the right into the packet on the left.  

Note: Windows has 2 forms of absolute paths: "C:\dir\file.txt" and "\dir\file.txt".  The second one refers to a file on the current drive.  The first is encoded: Root(absolute)->Directory("C:")->Directory("dir")->File("file.txt", ...)  And the second: Root(absolute)->Directory("dir")->File("file.txt", ...).  Thus, clients on Windows will need to look for Directory packets with drive names at the first level inside an absolute Root packet.  When it happens, they must change drives accordingly.




File System Specific Packets

The following packets are used to contain the metadata for specific file systems.  It is RECOMMENDED that clients write the packets for the particular file system that the client is run on.  It is also RECOMMENDED that clients support decoding the packets that they write.

The metadata often contains security-related features: ownership of files, etc..  Client authors need to take security seriously.  We do not want Par3 to become a method for hackers to attack our users' systems.  If a piece of metadata could be used to violate security, the default action of the client should be to ignore it or to query the user.  It is REQUIRED that the user's permission be granted for any action that might jeopardize their security.

In addition to the packet-specific information below, there is a separate section of this document devoted to security.  Client authors should follow it and investigate any common ways to hack their particular system.

Parchive 3.0 supports metadata for 2 file systems: a generic UNIX file system and FAT/FAT32/exFAT.  Parchive 3.0 supports hard and symbolic links for NFTS file systems, but NTFS's complete file permissions were too complicated to include in version 3.0.  Future versions of Parchive may support them.   Clients on an NFTS file system that need to preserve more than FAT permissions and hard/symbolic links will need to use another program to preserve them.  

The encoding client can write permissions as many file systems as chooses.  It can write none or write both UNIX permissions for a file and also FAT permissions for the same file.  The decoding client can choose to ignore all file-system specific permissions.  If it chooses to support them, it should prefer the permissions for its current file system.  (That is, prefer the Par3 file's UNIX permissions when on a UNIX file system and FAT permissions on an FAT system.)  If the permissions for the current file system are not in the Par3 file, the decoding client can attempt to translate the permissions in the Par3 file to the local system.  However, that should only be attempted with extreme caution, due to the potential for errors weakening security.


Link Packet

This packet represents a hard or symbolic link on UNIX and NTFS file systems.  (The FAT and exFAT file systems do not support links.)

The Link packet has a type value of "PAR LNK\0" (ASCII). The packet's body contains the following:

Table: Link Packet Body Contents
Length (bytes)	Type	Description
16	fingerprint hash        checksum of Directory or Root packet
2      unsigned int    length of string
?      UTF-8 string    name of symbolic link or hard link
4      unsigned int    length of path
?      {UTF-8 string}   path where NUL is the separator character

The fingerprint hash is the location of the link, either a Directory packet or a Root packet.  

The link's name are encoded as the length of the link's name and the UTF-8 string containing the name.

The length of the path and string of the path are last.  The path separator is the NUL character, the byte 0.  (In C, C++, and Java, it is written '\0'.)  If a path is an absolute path, the first character is NUL.  There is no NUL character at the end of the string.  Thus, a UNIX path "/usr/bin/bash" is encoded "\0usr\0bin\0bash", using the C convention of "\0" for the NUL character.  The path "src/foo.txt" would be encoded "src\0foo.txt".  (The previous strings do not follow the C convention of an implicit NUL at the end of the string.  There is no NUL at the end of the path.)  If the link is to a file in the input set, the names need to exactly match the names in the Directory and File packets.


Note: The length of the path is 4-byte unsigned int, rather than a 2-byte integer, because paths can be longer than individual file/directory names.

Note: Creating a link to file outside the input set is a serious security risk.  See the section of this document on security.


UNIX Permissions Packet

This packet holds the metadata from a generic UNIX system for one or more files and directories.  It is based on Linux's EXT4 file system, but does not capture all the details of that system.  

The UNIX File packet has a type value of "PAR UNX\0" (ASCII). The packet's body contains the following:

Table: UNIX File Packet Body Contents
Length (bytes)	Type	Description
8      signed int	atime, nanoseconds since the Epoch
8      signed int	ctime, nanoseconds since the Epoch
8      signed int	mtime, nanoseconds since the Epoch
4      unsigned int	owner UID 
4      unsigned int	group GID 
2      unsigned int	i_mode
2      unsigned int     number of extended attributes (xattr)
?*(4+?)		{2-byte unsigned int, UTF-8 string, 2-byte unsigned int, UTF-8 string}  xattr name-value pairs
2      unsigned int    length of string
?      UTF-8 string    name of owner
2      unsigned int    length of string
?      UTF-8 string    name of group
16*?	fingerprint hash        checksum of File, Directory, or Link packet


The times are all in nanoseconds since the Epoch, UTC.  They can hold EXT4's extended values.

Owner UID, Group GID are 32-bit values, also to hold EXT4's extended values.

The i_mode value is set using EXT4's values for the i_mode.  See https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout#Inode_Table   

The extended attributes are stored as a number of attributes followed by name-value pairs.  Both the name and value are stored as a 2-byte length of string followed by the UTF-8 contents of the string. 

The owner and group are also encoded as strings.  The decoding client gets to decide if owner/group are decided by UID/GID or by username/groupname.  (This is also how "tar" works.)

All of the above attributes are for the the File, Directory, or Link whose packet hashes are at the end of the packet.  Thus, the same attributes can be applied to multiple files, directories, or links at the same time.  

Note: On Linux with EXT4, the permissions of a symbolic link are ignored; the permissions of the target are always used.  On a MacOS and FreeBSD, symbolic links can have permissions different than their target.  For this reason, UNIX Permissions can contain hashes of Link packets.

Note: Different UNIX systems have different limits on the size of xattrs.   Linux's interface, the Virtual File System (VFS), limits all xattr names to fitting in 64kB and each value to fitting in 64kB.  EXT4 limits everything to fitting in 4kB.  BTRFS limits everything to 16kB.  Some file systems have no limit.  The choice of supporting values of only 16kB in length is probably sufficient for most uses.


FAT Permissions Packet

This packet holds the metadata from a FAT file system for one or more files and directories.  It is based on the exFAT specification.  It should capture all the user-visible details of that file system.  There are many vendor-specific modifications to the FAT system and this specification does not try to capture all of those details.  

The FAT File packet has a type value of "PAR FAT\0" (ASCII). The packet's body contains the following:

Table: UNIX File Packet Body Contents
Length (bytes)	Type	Description
1      bit field 	FileAttributes
4      unsigned int	CreateTimestamp
4      unsigned int	LastModifiedTimestamp
4      unsigned int	LastAccessedTimestamp
1      unsigned int	Create10msIncrement
1      unsigned int	LastModified10msIncrement
1      signed int	CreateUtcOffset
1      signed int	LastModifiedUtcOffset
1      signed int	LastAccessedUtcOffset

The first byte is the attributes bit field.  The bits are
Table: Attributes bit field
Bit index	  Attribute
0   ReadOnly 
1   Hidden
2   System
3   not used ("Volume")
4   Directory
5   Archive
6   not used ("Device")
7   not used ("Reserved")

The "Timestamp" fields record the time in local time, accurate to 2 seconds.  It is the number of seconds since midnight Jan. 1st, 1980, divided by 2.

The "10msIncrement" fields record the time down to a 10ms resolution.  These unsigned integers can only have values from 0 to 199.

The "UtcOffset" fields record the time difference between UTC and local time.  The unit is 15 minute increments.  The value 1 means that local time is UTC + 00:15.

Note: Times are unsigned and relative to Jan. 1st, 1980.  This is different from UNIX times that are signed and relative to Jan. 1st. 1970.

Note: The Timestamp fields are stored as unsigned ints, and not the year/month/day/hour/minute/doubleseconds format in the exFAT specification.

Note: There is no LastAccessed10msIncrement.





Permissions Grouping Packet

This packet represents a node in a tree containing all the file-system specific packets.  It exists so that the decoding client can determine when all file-system specific packets have been received.

The Permissions Grouping packet has a type value of "PAR GRP\0" (ASCII). The packet's body contains the following:

Table: Permissions Grouping Packet Body Contents
Length (bytes)	Type	Description
16	fingerprint hash       checksum of Root packet, or all zeroes
16*?	fingerprint hash       checksum of Link, UNIX Permissions, NTFS Permissions, FAT Permissions, or Permissions Grouping packets

The checksum of the Root packet is present if this packet is the root of the tree of Permissions Grouping packets.  If this is just an intermediate node, the value is all zeros.

The list of checksums represents the contents of the tree.  It can be any of the file-system specific packets, like the hashes of the Link, Unix Permissions, NTFS Permissions, or FAT Permissions packets.  It can also contain branches of the tree, by containing the hash of another Permissions Grouping Packet.

A tree of Permission Grouping packets cannot assign multiple permissions to the same File or Directory for the same file system.  For example, there cannot be two UNIX Permissions packets containing the same File packet's hash.  It is possible for there to be multiple permissions packets for the same File or Directory for different file systems.  These represent "on a Linux system, the file should have X permissions, and on an NTFS system, the file should have Y permissions".

Note: While it is possible to use Permissions Grouping packets to make a linked list containing the file-system specific packet hashes, it is RECOMMENDED that the encoding client create a shallow tree.



Security:

Security is a major issue for Parchive clients.  Users will probably execute the client on untrusted files, downloaded from strangers.  We do not want Parchive to be a means for hackers to attack a system.

There are three major ways for hackers to attack using a Par3 file.  The first is to get the client to run untrusted code.  The second means of attack is to get the client to create or modify important files, such as overwriting the password file.  The last attack is a "denial of service" where the attacker fills the hard drive completely.  (Most OSes need some empty space on a drive to operate.)   

The first means of attack is for hackers to get the client to run untrusted code.  The most common example of this is a "buffer overflow attack".  The design of the Par3 file format is made to avoid buffer overflow attacks.  Every region of data has an explicit lengths.  Strings are not NUL-terminated.  This forces client writers to think about the sizes of buffers and how they use them.

Client writers can find buffer overflows and other bugs using "fuzzing".  Fixing those bugs will prevent hackers from being able to trick the client into running untrusted code.

The second means of attack is to hack the file system.  That is, to have the client modify the data or the permissions of an important file that the system will read/execute or the user will unintentionally execute.  (We accept that the user can always intentionally run a program sent in an untrusted Par3 file.)  An example of a hack of the file system is to overwrite the file containing usernames and passwords.

Avoiding file system attacks takes care.  Especially if the client is designed to run on multiple file systems and OSes.  Each system has different vulnerabilities and all of them must be taken into account.

One part of preventing these attacks is confirming that filenames are valid filenames.  A filename should not contain a '\0' in the middle of it.  It should not be a path (e.g., not contain "/" on a UNIX system or "\" on a Windows system.  MacOS also accepts ":".).   The filename should not violate conventions (e.g., on UNIX, be named "." or "..".).  It should not reference a networked file name or device name.  (E.g., Windows does not allow "COM0", "LPT0", and many more.)

Slightly off the topic of security, this is probably a good place to recommended that users be warned when they create Par3 files with names that are incompatible with Windows, Mac, or Linux systems. That is, file or directory names that are more than 255 characters long, start with a period (.) or a dash (-), or contain one of these characters: < > : " ' ` ? * & | [ ] \ ; or newline (\n).

\/ \/ \/ TODO \/ \/ \/

Should we Include #, !, and (windows) %

/\ /\ /\ TODO /\ /\ /\


Another part of preventing file system attacks is to validate paths.  For paths, major attacks will come by referencing a file using an absolute path ("/etc/passwd" or "C:\Windows\System32\Config") or escaping a subdirectory ("../../etc/passwd" or "..\..\Windows\System32\Config").   (NOTE: On Windows, an absolute path can start "C:\" or "\" or "\\" for example. For UNIX, that means one starting with "/" or "//" or "~". For Mac, one can also start with ":".  There may be other formats!)  It is REQUIRED that the client get user approval before using an absolute path or using a feature like ".." in a path.   For a GUI, this approval can come via a dialog box saying something like "This Par3 file is writing to an absolute path.  This is dangerous, because it can overwrite system files like your password file.  Do you want to allow this?"  For a command line tool, the approval can come via a command line option.  The default should always be to not allow this behavior.

Clients are also REQUIRED to ask for permission when linking to files outside a subdirectory.  That is, if the link target contains an absolute path or uses a feature like "..".

Other attacks can come through file attributes.  It is doubtful that setting a file to be "read-only" or changing its creation time will be part of an attack.  But some attributes are means of attack.  Clients SHOULD warn users when a file is marked "executable".  Especially if the file is added to a place where users execute command.  (E.g., on UNIX, a hacker might write a program called "ls" into a directory in the user's PATH.)  Clients need to be careful when setting the owner of a file.  Client writers need to know the common attacks on their platforms.  (E.g., on UNIX, any file with both the "others may write" permission and the "Set UID" permission is a security hazard.)  Clients are REQUIRED to get approval for any action that might compromise security.

The third and last attack is one that fills up the entire file system.  This is a "denial of service" attack, because most OSes cannot run when the file system is full.  This attack is a possibility because it is not hard to create the Parchive equivalent of a "ZIP bomb": a small file that writes a stupendous amount of data to the file system.  Client writers should also worry about this attack, because user may accidentally fill up their entire file system.  

Client writers can avoid this error by checking the amount of free disk space before writing.  Client writers should also be aware of OS return values that indicate that free space is exhausted.  (E.g., on Linux, the write() system call can generate errors ENOSPC and EDQOUT.)

Earlier versions of Parchive avoided including file permissions in the standard, because security issues are difficult to get right.  Please take security seriously.  


Order of Packets:

In order for a client to do single-pass recovery, the recommended order of packets is:

Creator
Start
Matrix 
Data or External Data
Root
Recovery Data

The Matrix packets contain information (often hints) at how many buffers the receiver will have to allocate for the recovery data. 

Some vital packets (Start, Matrix, Root) are not recoverable using the Recovery data.  Those packets will need to be repeated, at different places in the file.

Single-pass recovery is only possible in some cases.  If the packets do not arrive in the order above, a client will have to fall back to a multi-pass recovery algorithm.



Galois Field Encoding

Parchive 3.0 supports any Galois field that is a multiple of 2^8.  That is, any Galois field that fits neatly in one or more bytes.  Clients must support every possible Galois field.

Clients are expected to optimize performance for specific Galois fields.  Some likely targets for optimization are:

Table: Common Galois fields
Size (bits)    Generator (hexadecimal)
8              0x11D
16             0x1100B
128            (1 << 128) + 0x43 

NOTE: The 8-bit Galois field is used by many error correction applications, including some implementations of RAID6.  

Note: The 8-bit Galois field with generator 0x11B is used by AES encryption and is supported by the x86 instruction GF2P8MULB.  However, it tends not to be used for error correction, because it does not have a "primitive element".   (See https://en.wikiversity.org/wiki/Talk:Reed%E2%80%93Solomon_codes_for_coders#The_magic_number_0x11D_(0b100011101))

Note: The 16-bit Galois field is the same as in Par 2.0.

Note: All 64-bit Galois fields are supported by the x86 instruction CLMUL.

Note: The 128-bit Galois field is implemented by Intel in this white paper:
https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/carry-less-multiplication-instruction-in-gcm-mode-paper.pdf

Note: The ARM processor has an instruction extension called "NEON" with a VMULL instruction.  VMULL.P8 will do eight 8-bit Galois field multiplications at once.



Incremental Backup

The Parchive 3.0 specification has been written so that new Par3 files can be written that reuse the recovery data in existing Par3 files.  This is (badly) called "incremental backup".

An incremental backup only makes sense when the new set of input files has a lot of overlap with the previous set of input files.  The most common usage is when a user has added (relatively few) files to a directory tree or renamed files.  The incremental backup supports any changes, including changing files or deleting files, but it becomes less efficient with more and larger changes.

An "incremental backup" is created by writing the InputSetID of the "parent" into the Start packet of the "child".  The child must have the same block size, Galois field, and Galois field generator as the parent.

The child will have a new Root packet, which determines the input set for the incremental backup.  The child can reuse File, Directory, and file-system specific packets from the parent to encode that input set.  The child will have to contain new File packets for all the files that have changed and new Directory packets when the contents of the directory or any of its subdirectories have changed.  So, if a single file has changed, there will be one new File packet and a new Directory packet for every directory above it.  And, of course, the new Root packet.

If any file data has changed or been added, the child will have new input blocks.  These are assigned indices greater than any index used by a parent's input block.  The lowest input block index that went unused by the parent is written into the parent's Root packet.

If a file's contents have changed, it may be possible to reuse the data in the parent's version of the file.  The rolling hash of the parent's input blocks can be used to find that data's location in the child's version of the file.  A chunk can be created in the child's File packet to record the overlap.  Reusing data from the parent's input blocks is not required, but can save a lot of storage and significantly increase the probability of a recovering data.



Par Inside Another File

Par3 packets can be used to protect the file in which they are stored.  They cannot protect all of the file, because Par3 packets only protect the input data and not themselves.  When Par3 data is used inside another file format to protect it, we call it "Par inside".  So, if Par3 data protects a ZIP file, we call it "Par inside ZIP".

An example of using Par-inside is with the ZIP file format.  The ZIP file format stores compressed files at the front and the list of all files at the end, but, inbetween, space can be used for any data without affecting the ZIP file's contents.  Par3 packets can put in this space.  The Par3 packets can protect the start and end of the file, where ZIP stores its data.  This way, if the file ever gets damaged, the Par3 packets can be used to fix the ZIP data.  It is a file that contains data to repair itself.

To make Par-inside work, the Par3 packets need to contain one File packet, which refers to the file itself.  Thus, the name in the File packet must match the name of the file.  The File packet's chunk descriptions need checksums for the protected portions of the file and need to have zeroed checksums for where the Par3 packets will be written into the file.  In the case of the ZIP file, only the start and end of the file would have chunk descriptions with checksums.  The middle of the file, where the Par3 packets are stored, would have a chunk description with a zeroed checksum.  Obviously, External Data packets would be used and not Data packets.

It is possible to protect the non-redundant parts of a Par3 file using "Par inside".  This is called "Par inside Par".  Thus, instead of repeating vital packets (Start, Matrix, Root File, Directory, and Root packets), the sections of the file containing them would be protected using "Par inside".  The Par-inside packets would be distinguishable from the "outside" Par3 packets because they would have a different InputSetID.  

The "inside" Par3 packets cannot protect themselves.  The vital "inside" Par3 packets would still need to be repeated and spread through out the file.  The "Par inside Par" concept only makes sense if the vital "outside" Par3 packets took up a lot of space.   For example, when storing a large number of files.  Then, the space used by vital "inside" Par3 packets would be much smaller than the vital "outside" Par3 packets and repeating the vital inside Par3 packets would shrink the overhead and minimize the amount of data could make the Par3 file unusable.


Alignment:

In Par2, the packets were forced to be "4-byte aligned".  That is, packet lengths were always a multiple of 4 and the first byte of X-byte integers always had an index in the packet that was a multiple of X.  Par3 has dropped the requirement that packets be aligned.

Still, some processors --- either old ones like ARMv5 or new ones with SIMD instructions --- have significantly higher performance when values are aligned in memory.  Par3 dropped the alignment requirement because there isn't a single alignment that works for all these processors.  ARMv5 requires 4-byte alignment and some x86 AVX instructions require 64-byte alignment.

Par3 does not require packets to be aligned, but a client author can introduce alignment to Data packets and Recovery Data packets written by their client by choosing an appropriate block size and inserting zero-byte padding before these packets.  Remember, though, that a client must be able to read every file and not every client will generate aligned packets.  And, in any case, alignment in any file can be thrown off when a byte is lost or gained during transmission.  So, while a receiving client may run faster when a packet is aligned, it must still work properly if the packets are not aligned.  

In short, a client author can introduce alignment into their own files to increase performance, but cannot require alignment in all files.  


Rolling Hash:

The rolling hash is intended to find input blocks that have moved inside an input file.  The rolling hash is fast, but imperfect.  Thus, the rolling hash matches, the client will test the possible input block with the slower-to-compute fingerprint hash.  But, when data is repetitive, this can lead to a problem.

The problem with repetitive data is that many locations can match the rolling hash.  Then, the slower fingerprint hash is computed at all those locations and the process of finding input blocks slows to a snail's pace.

This problem doesn't occur if the user compressed the data before writing the Par3 file, because a compressed file is almost random.  But the decoding client can't rely on the data being compressed.

The decoding client solve the problem of many blocks matching the rolling hash in many ways.  One approach is to count the number of matches for each rolling hash value.  If there many matches over a small area of the file, the client can ignore that rolling hash value for a while.

Another approach is to scan a file twice.  The first pass looks for all blocks that match the value of a rolling hash.  The second pass computes the fingerprint hashes, prioritizing blocks that match a unique rolling hash value and blocks that do not overlap other blocks.  


Conventions:

The above is the official spec.  It is what all clients must implement.  This section discusses conventions, which are what most clients will want to do, so that users have a common expectation of how a Parchive client behaves.

Par3 files should always end in ".par3". For example, "file.par3". If a file contains recovery blocks, the ".par3" should be preceded by ".volXX+YY" where XX is the number of previous recovery blocks and YY represent the number of recovery blocks in this file. For example, "file.vol20+10.par3" means this starts with the 20th recovery block and contains 10 recovery blocks.  More than 2 digits should be used if necessary. Any numbers that contain fewer digits than the largest exponent should be preceded by zeros so that all filenames have the same length. For example, "file.vol075+10.par2".  Numbers should start at 0 and go upwards.

If a Par3 file contains input blocks, the ".par3" should be preceded by ".partXX+YY", where XX is the number of previous input blocks and YY is the number in this file.  

If multiple Par3 files are generated, they may either contain a constant number of blocks per file (e.g. 20, 20, 20, ...) or exponentially increasing number of blocks (e.g., 1, 2, 4, 8, ...). Note that to store 1023 blocks takes 52 files if each has 20 blocks, but takes only 10 files with the exponential pattern.

When generating multiple Par3 files, it is expected that one file be generated without any Recovery Data packets and containing all the packets needed to verify correct transmission of the files.  That is, contain the Start, External Data, File, Directory, and Root packets.  It may also contain the Matrix packets.

The other files should either (1) include duplicates of all those vital packets or (2) use "Par inside Par" to protect damage to them.  "Par inside Par" is creating using Par3 packets with a different InputSetID.  That input set would contains the Par3 file itself as an input file.  "Par inside Par" is useful when the space taken up by the vital packet is large.  Duplicating it would take up a lot of space.  When using "Par inside Par", the outer Par3 data would only need to protect 1 file and duplication of its vital packets would not take up much space.

If just a single Par3 file is generated, it is expected that the vital packets are repeated multiple times and scattered through out the file. (Once again, repeating data that cannot be recovered.)  Or, "Par inside Par" data can be generate and scattered through out the file.

Recall that all files must contain a creator packet.



Conclusion:

Parchive 3.0 is a big step over Parchive 2.0.  It has new capabilities (Par-inside, incremental backups), expanded capabilities (more than 2^16 blocks/files) and is very flexible (any Galois field and any code matrix).  We hopes its current users enjoy the new features and we hope that Par 3.0 finds new uses.  


A. How to Add an Application-Specific Packet Type

Say the author of "NewsPost" wanted to add his own packet type - one that identified the names of the Usenet messages in which the files are posted. That author can create his own packet type. For example, here is the layout for one where the Usenet messages are identified by a newsgroup and a regular expression which all matches the names of the Usenet articles.

The packet has a type value of "NPstMSGS" (ASCII).  The author chose the prefix "NPst" for his client, "NewsPost", which prevents collisions with other clients.  The packet's body contains the following:

Table B.3. Example Application Specific Packet
Length (bytes)	Type	Description
16	fingerprint hash	The checksum of the File packet
2	unsigned int	The length of the string containing the name of the newsgroup. 
?	UTF-8 string	The name of the newsgroup. For example, "alt.binaries.multimedia".
2	unsigned int	The length of the string containing the regular expression.
?       UTF-8 string	A regular expression matching the name of articles containing the file. For example, "Unaired Pilot - VCD,NTSC - (??/??)".


Appendix B:

\/ \/ \/ TODO \/ \/ \/

License text

/\ /\ /\ TODO /\ /\ /\



\/ \/ \/ TODO \/ \/ \/

NTFS Permissions Packet

"Standard information": read-only, read/write, and so forth, timestamp, and link count.
Short name (8.3 case-insensative format), POSIX name, and "shared namespace" name
multiple named data attributes  (e.g., thumbnail icons, etc.)
Object ID, Birth Volume Id, Birth Object Id,  Domain Id



NTFS docs by Linux driver developers:
https://dubeyko.com/development/FileSystems/NTFS/ntfsdoc.pdf


https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc781134(v=ws.10)

https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-fscc/a82e9105-2405-4e37-b2c3-28c773902d85

$STANDARD_INFORMATION according to https://flatcap.org/linux-ntfs/ntfs/attributes/standard_information.html

0x00 	8 	  	C Time - File Creation
0x08 	8 	  	A Time - File Altered
0x10 	8 	  	M Time - MFT Changed
0x18 	8 	  	R Time - File Read
0x20 	4 	  	DOS File Permissions
0x24 	4 	  	Maximum Number of Versions
0x28 	4 	  	Version Number
0x2C 	4 	  	Class Id
0x30 	4 	2K 	Owner Id
0x34 	4 	2K 	Security Id
0x38 	8 	2K 	Quota Charged
0x40 	8 	2K 	Update Sequence Number (USN)

$FILE_NAME according to https://flatcap.org/linux-ntfs/ntfs/attributes/file_name.html

0x00 	8 	File reference to the parent directory.
0x08 	8 	C Time - File Creation
0x10 	8 	A Time - File Altered
0x18 	8 	M Time - MFT Changed
0x20 	8 	R Time - File Read
0x28 	8 	Allocated size of the file
0x30 	8 	Real size of the file
0x38 	4 	Flags, e.g. Directory, compressed, hidden
0x3c 	4 	Used by EAs and Reparse
0x40 	1 	Filename length in characters (L)
0x41 	1 	Filename namespace
0x42 	2L 	File name in Unicode (not null terminated)

Timestamps from https://www.forensixchange.com/posts/19_04_22_win10_ntfs_time_rules/

NTFS timestamps are stored as 64-bit unsigned little-endian integers. The resolution of the timestamps is 100 nanoseconds counting from Jan 1, 1601, and all of them are stored in UTC format.

$FILE_NAME timestamps can only be changed by kernel.  $STANDARD_INFORMATION ones can be changed by user.

https://flylib.com/books/en/2.48.1/standard_file_attributes.html

ACL access control list
? "ADS = Alternative Data Stream"?

/\ /\ /\ TODO /\ /\ /\
